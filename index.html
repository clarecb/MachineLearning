<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Coursera Machine Learning by clarecb</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Coursera Machine Learning</h1>
      <h2 class="project-tagline">Course project</h2>
      <a href="https://github.com/clarecb/MachineLearning" class="btn">View on GitHub</a>
      <a href="https://github.com/clarecb/MachineLearning/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/clarecb/MachineLearning/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p>&lt;!DOCTYPE html&gt;</p>

<p></p>

<p></p>

<p>

</p>

<p></p>Practical Machine Learning Course Project



<p>
</p>







code{white-space: pre;}

<p></p>




  pre:not([class]) {
    background-color: white;
  }




<p></p>

<p></p>


.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}


<div>


<div id="header">
<h1>
<a id="practical-machine-learning-course-project" class="anchor" href="#practical-machine-learning-course-project" aria-hidden="true"><span class="octicon octicon-link"></span></a>Practical Machine Learning Course Project</h1>
</div>

<div id="overview">
<h1>
<a id="overview" class="anchor" href="#overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overview</h1>
<p>This project uses data from personal activity measuring devices to predict which of 5 ways an individual performed a particular exercise (barbell lift). Two machine learning algorithms were used to create a predictive model. The random forest model was found most accurate.</p>
</div>

<div id="setting-options-for-the-analysis">
<h1>
<a id="setting-options-for-the-analysis" class="anchor" href="#setting-options-for-the-analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Setting options for the analysis</h1>
<p>Packages were loaded that were used throughout this project, and the <strong><code>options</code></strong> function was used to turn off scientific notation. Also, the working directory and the seed were set.</p>
<pre><code>library(downloader)
library(knitr)
library(rmarkdown)
library(caret)</code></pre>
<pre><code>## Loading required package: lattice
## Loading required package: ggplot2</code></pre>
<pre><code>library(randomForest)</code></pre>
<pre><code>## randomForest 4.6-10
## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code>options(scipen = 999)
setwd("~/GoogleDrive/R/MachineLearning")
set.seed(500)</code></pre>
</div>

<div id="downloading-the-data-and-exploratory-analysis">
<h1>
<a id="downloading-the-data-and-exploratory-analysis" class="anchor" href="#downloading-the-data-and-exploratory-analysis" aria-hidden="true"><span class="octicon octicon-link"></span></a>Downloading the data and exploratory analysis</h1>
<p>The data files were downloaded to the working directory and then loaded into R.</p>
<pre><code>if (!file.exists("training.csv")) {
    fileurl = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
    download(fileurl, "training.csv", mode = "wb")
}

if (!file.exists("testing.csv")) {
    fileurl2 = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
    download(fileurl2, "testing.csv", mode = "wb")
}


training = read.csv("training.csv", na.strings = c("NA", 
    "#DIV/0!", ""))
testing = read.csv("testing.csv", na.strings = c("NA", 
    "#DIV/0!", ""))</code></pre>
<p>A table was created to get an understanding of how many observations were in each <strong><code>classe</code></strong> of exercise type. Also, the <strong><code>str</code></strong> function was used to get an understanding of the structure of the variables in the datasets (the results of this function are hidden form this document because of its length).</p>
<pre><code>str(training)</code></pre>
<pre><code>table(training$classe)</code></pre>
<pre><code>## 
##    A    B    C    D    E 
## 5580 3797 3422 3216 3607</code></pre>
<p>The first 7 rows, which were not needed for the analysis, were removed. Also, some columns have a high percentage of missing values. Rows with more than 50% <strong><code>NA</code></strong> values were removed from the training dataset.</p>
<pre><code>trainingID = training[, 8:length(colnames(training))]
trainingNA = trainingID[, !colSums(is.na(trainingID)) &gt;= 
    (0.5 * nrow(trainingID))]</code></pre>
</div>

<div id="creating-the-models">
<h1>
<a id="creating-the-models" class="anchor" href="#creating-the-models" aria-hidden="true"><span class="octicon octicon-link"></span></a>Creating the models</h1>
<p>A subset of the training dataset was created for cross validation. The training dataset was subset into 60% to create the model and 40% to test the prediction model.</p>
<pre><code>inTrain = createDataPartition(y = training$classe, 
    p = 0.6, list = FALSE)
trainingsubset = trainingNA[inTrain, ]
trainingtest = trainingNA[-inTrain, ]
trainingsubset = as.data.frame(trainingsubset)</code></pre>
<p>Based on my understanding of types of machine learning regression models, a random forest alogrithm and a logit boosting algorithm were both used to create a predictive model with this data. Both models incorporated preprocessing using Principal Component Analysis, and each was cross-validated against the 40% testing subset (<strong><code>trainingtest</code></strong>) of the original training dataset.</p>
<pre><code>fitRF = randomForest(classe ~ ., data = trainingsubset, 
    method = "class", preProcOptions = "pca")
fitLB = train(classe ~ ., data = trainingsubset, method = "LogitBoost", 
    preProcess = "pca")</code></pre>
<pre><code>## Loading required package: caTools
## Loading required namespace: e1071</code></pre>
</div>

<div id="model-predicitons-and-cross-validation">
<h1>
<a id="model-predicitons-and-cross-validation" class="anchor" href="#model-predicitons-and-cross-validation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Model predicitons and cross-validation</h1>
<pre><code>predictRF = predict(fitRF, trainingtest, type = "class")
CMRF = confusionMatrix(predictRF, trainingtest$classe)
CMRF</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2231    4    0    0    0
##          B    1 1511   13    0    0
##          C    0    3 1353   19    1
##          D    0    0    2 1267    3
##          E    0    0    0    0 1438
## 
## Overall Statistics
##                                                
##                Accuracy : 0.9941               
##                  95% CI : (0.9922, 0.9957)     
##     No Information Rate : 0.2845               
##     P-Value [Acc &gt; NIR] : &lt; 0.00000000000000022
##                                                
##                   Kappa : 0.9926               
##  Mcnemar's Test P-Value : NA                   
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9996   0.9954   0.9890   0.9852   0.9972
## Specificity            0.9993   0.9978   0.9964   0.9992   1.0000
## Pos Pred Value         0.9982   0.9908   0.9833   0.9961   1.0000
## Neg Pred Value         0.9998   0.9989   0.9977   0.9971   0.9994
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2843   0.1926   0.1724   0.1615   0.1833
## Detection Prevalence   0.2849   0.1944   0.1754   0.1621   0.1833
## Balanced Accuracy      0.9994   0.9966   0.9927   0.9922   0.9986</code></pre>
<p>The random forest method created a model with <strong>99.413714</strong> percent accuracy.</p>
<pre><code>predictLB = predict(fitLB, trainingtest)
CMLB = confusionMatrix(predictLB, trainingtest$classe)
CMLB</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1311  172  206   91   48
##          B   86  545   73  131  151
##          C   88  106  339   91   52
##          D   38   53   32  440   58
##          E   65  115   89   73  715
## 
## Overall Statistics
##                                                
##                Accuracy : 0.6482               
##                  95% CI : (0.635, 0.6612)      
##     No Information Rate : 0.3073               
##     P-Value [Acc &gt; NIR] : &lt; 0.00000000000000022
##                                                
##                   Kappa : 0.5468               
##  Mcnemar's Test P-Value : &lt; 0.00000000000000022
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.8256   0.5499   0.4587  0.53269   0.6982
## Specificity            0.8556   0.8944   0.9239  0.95831   0.9175
## Pos Pred Value         0.7172   0.5527   0.5015  0.70853   0.6764
## Neg Pred Value         0.9171   0.8934   0.9110  0.91511   0.9248
## Prevalence             0.3073   0.1918   0.1430  0.15983   0.1981
## Detection Rate         0.2537   0.1055   0.0656  0.08514   0.1384
## Detection Prevalence   0.3537   0.1908   0.1308  0.12016   0.2045
## Balanced Accuracy      0.8406   0.7222   0.6913  0.74550   0.8079</code></pre>
<p>The logit boosting method created a model with <strong>64.8219814</strong> percent accuracy.</p>
</div>

<div id="out-of-sample-error">
<h1>
<a id="out-of-sample-error" class="anchor" href="#out-of-sample-error" aria-hidden="true"><span class="octicon octicon-link"></span></a>Out-of sample error</h1>
<p>By subtracting this accuracy from the value of <strong><code>100</code></strong> , the out-of-sample percent error can be estimated. For the random forest method, the out-of-sample error can be estimated to be <strong>0.586286</strong> percent. The out-of-sample error for the logit boosting method can be estimated to be <strong>35.1780186</strong> percent. From this analysis, the random forest method is the most accurate.</p>
</div>

<div id="conclusions">
<h1>
<a id="conclusions" class="anchor" href="#conclusions" aria-hidden="true"><span class="octicon octicon-link"></span></a>Conclusions</h1>
<p>Since the random forest model has <strong>99.413714</strong> percent accuracy, it can be used to accurately predict the type of class of barbell exercise an individual performed.</p>
</div>

<div id="code-for-problem-online-submission">
<h1>
<a id="code-for-problem-online-submission" class="anchor" href="#code-for-problem-online-submission" aria-hidden="true"><span class="octicon octicon-link"></span></a>Code for problem online submission</h1>
<pre><code>testinganswers = predict(fitRF, testing, type = "class")

pml_write_files = function(x) {
    n = length(x)
    for (i in 1:n) {
        filename = paste0("problem_id_", i, ".txt")
        write.table(x[i], file = filename, quote = FALSE, 
            row.names = FALSE, col.names = FALSE)
    }
}

pml_write_files(testinganswers)</code></pre>
</div>

<p></p>
</div>







      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/clarecb/MachineLearning">Coursera Machine Learning</a> is maintained by <a href="https://github.com/clarecb">clarecb</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
